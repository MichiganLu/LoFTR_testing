{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57d9dcef",
   "metadata": {},
   "source": [
    "# The following blocks of codes are for pruning purpose.\n",
    "### The difference between this and the original pruning experiment is that the training data is all randomly generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54fc1d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "from src.utils.plotting import make_matching_figure\n",
    "from pathlib import Path\n",
    "import torch_pruning as tp\n",
    "from src.loftr.backbone import build_backbone\n",
    "from src.loftr.backbone.resnet_fpn import BasicBlock\n",
    "\n",
    "from einops.einops import rearrange\n",
    "\n",
    "from src.loftr.utils.position_encoding import PositionEncodingSine\n",
    "from src.loftr.loftr_module import LocalFeatureTransformer, FinePreprocess\n",
    "from src.loftr.utils.coarse_matching import CoarseMatching\n",
    "from src.loftr.utils.fine_matching import FineMatching\n",
    "from src.loftr import LoFTR, default_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa8a1eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default config uses dual-softmax.\n",
    "# The outdoor and indoor models share the same config.\n",
    "# You can change the default values like thr and coarse_match_type.\n",
    "_default_cfg = deepcopy(default_cfg)\n",
    "_default_cfg['coarse']['temp_bug_fix'] = True  # set to False when using the old ckpt\n",
    "original_backbone = build_backbone(_default_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f42a6d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "backbone_weight = OrderedDict()\n",
    "remain_weight = torch.load(\"./weights/indoor_ds_new.ckpt\")['state_dict']\n",
    "for k in list(remain_weight.keys()):\n",
    "    if k.startswith('matcher.backbone.'):\n",
    "        backbone_weight[k.replace('matcher.backbone.', '', 1)] = remain_weight.pop(k)\n",
    "original_backbone.load_state_dict(backbone_weight)\n",
    "new_backbone = deepcopy(original_backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a1d81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(model):\n",
    "    model.cpu()\n",
    "    DG = tp.DependencyGraph().build_dependency( model, torch.randn(1, 1, 480, 640) )\n",
    "    def prune_conv(conv, amount=0.2):\n",
    "        #weight = conv.weight.detach().cpu().numpy()\n",
    "        #out_channels = weight.shape[0]\n",
    "        #L1_norm = np.sum( np.abs(weight), axis=(1,2,3))\n",
    "        #num_pruned = int(out_channels * pruned_prob)\n",
    "        #pruning_index = np.argsort(L1_norm)[:num_pruned].tolist() # remove filters with small L1-Norm\n",
    "        strategy = tp.strategy.L1Strategy()\n",
    "        pruning_index = strategy(conv.weight, amount=amount)\n",
    "        plan = DG.get_pruning_plan(conv, tp.prune_conv, pruning_index)\n",
    "        plan.exec()\n",
    "    \n",
    "    block_prune_probs = [0.05, 0.05, 0.1, 0.1, 0.1, 0.1]\n",
    "    blk_id = 0\n",
    "    for m in model.modules():\n",
    "        if isinstance( m, BasicBlock ):\n",
    "            prune_conv( m.conv1, block_prune_probs[blk_id] )\n",
    "            prune_conv( m.conv2, block_prune_probs[blk_id] )\n",
    "            blk_id+=1\n",
    "    return model\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop((480,640)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5)\n",
    "])\n",
    "    \n",
    "def get_random_img(img_list):\n",
    "    img = cv2.imread(img_list[np.random.randint(0,len(img_list))], cv2.IMREAD_GRAYSCALE)\n",
    "    #img = cv2.resize(img, (640, 480))\n",
    "    img = torch.from_numpy(img)[None][None] / 255.     #return an image tensor\n",
    "    img = transform(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33af2313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prune model\n",
    "#prune_model(new_backbone)\n",
    "new_backbone = torch.load('./temp_backbone/untrain.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97962eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the retrain img list\n",
    "img_list = []\n",
    "for path in Path('/home/cvte-vm/Datasets/ScanNet/scannet_test_1500').rglob('*.jpg'):\n",
    "    img_list.append(str(path))\n",
    "for path in Path('/home/cvte-vm/Datasets/Megadepth/megadepth_test_1500').rglob('*.jpg'):\n",
    "    img_list.append(str(path))\n",
    "    \n",
    "#knowledge distillation\n",
    "#freeze original model\n",
    "for name, param in original_backbone.named_parameters():                \n",
    "    param.requires_grad = False\n",
    "original_backbone = original_backbone.cuda()\n",
    "original_backbone.eval()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(new_backbone.parameters(), lr=0.02, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95, last_epoch=-1, verbose=False)\n",
    "\n",
    "num_epoch = 4\n",
    "num_step = 300\n",
    "batch_size = 8\n",
    "\n",
    "best_model_wts = deepcopy(new_backbone.state_dict())\n",
    "def iterative_pruning(prune_time, criterion, optimizer, scheduler, original_backbone, new_backbone):\n",
    "    for time in range(prune_time):\n",
    "        print()\n",
    "        print('**************************')\n",
    "        print(f\"starting the {time} prune\")\n",
    "        #prune model\n",
    "        #prune_model(new_backbone)\n",
    "        new_backbone = new_backbone.cuda()\n",
    "        new_backbone.train()\n",
    "        epoch_loss_old = 100\n",
    "        num_param = sum(p.numel() for p in new_backbone.parameters())\n",
    "        print(f\"total parameters for backbone is now {num_param} after pruning, now start retrain\")\n",
    "        #start retrain\n",
    "        for i in range(num_epoch):\n",
    "            print(f\"now learning rate becomes {optimizer.param_groups[0]['lr']}\")\n",
    "            running_loss = 0.0\n",
    "            for j in range(num_step):    \n",
    "                #first prepare data batch\n",
    "                img = get_random_img(img_list)             #first img in a batch\n",
    "                #for bs in range(batch_size-1):\n",
    "                    #img1 = get_random_img(img_list)\n",
    "                    #img = torch.cat([img, img1], dim=0)    #concatenate in batch dimension, now img is a batch\n",
    "                img = torch.randint(0,256,(8,1,480,640))/255.0\n",
    "                #print(img*255)\n",
    "                img = img.cuda()\n",
    "                #finding loss\n",
    "                optimizer.zero_grad()\n",
    "                (layer2_label, layer4_label) = original_backbone(img) #soft label from teacher\n",
    "                (layer2_student, layer4_student) = new_backbone(img)  #student prediction\n",
    "                loss1 = criterion(layer2_student, layer2_label)\n",
    "                loss2 = criterion(layer4_student, layer4_label)\n",
    "                total_loss = loss1+loss2\n",
    "                total_loss.backward()\n",
    "                optimizer.step()        \n",
    "                if j%10 == 0:\n",
    "                    print('step'+str(j)+' loss is {:.4f} '.format(total_loss))\n",
    "\n",
    "                #calculating loss to check training result\n",
    "                running_loss += total_loss.item() * batch_size\n",
    "            epoch_loss = running_loss/(num_step*batch_size)\n",
    "            print('*******epoch loss is {:.4f} '.format(epoch_loss))\n",
    "\n",
    "            if epoch_loss < epoch_loss_old:    #save if loss gets smaller\n",
    "                epoch_loss_old = epoch_loss\n",
    "                best_model_wts = deepcopy(new_backbone.state_dict())\n",
    "            if epoch_loss < 0.07:             #good enough, start next prune\n",
    "                torch.save(new_backbone, '/home/cvte-vm/Deep_Feature_Extract/LoFTR/temp_backbone/backbones'+str(time)+'.pth')\n",
    "                torch.save(new_backbone.state_dict(), '/home/cvte-vm/Deep_Feature_Extract/LoFTR/temp_backbone/backbones'+str(time)+'.dict')\n",
    "                for g in optimizer.param_groups:\n",
    "                    g['lr'] = 0.0003*(2**time)\n",
    "                break                         \n",
    "            lr_scheduler.step()               #decay the learning rate for next epoch\n",
    "        \n",
    "        for g in optimizer.param_groups:      #reset learning rate for next prune\n",
    "            g['lr'] = 0.0003*(2**time)\n",
    "        if epoch_loss > 0.1:                 #if the loss cannot be optimized anymore, then stop pruning\n",
    "            print(f\"can only prune {time+1} time, cannot continue\")\n",
    "            new_backbone.load_state_dict(best_model_wts)\n",
    "            return new_backbone\n",
    "        else:                                  #when 0.07<loss<0.10, you still save the model\n",
    "            torch.save(new_backbone, '/home/cvte-vm/Deep_Feature_Extract/LoFTR/temp_backbone/backbones'+str(time)+'.pth')\n",
    "            torch.save(new_backbone.state_dict(), '/home/cvte-vm/Deep_Feature_Extract/LoFTR/temp_backbone/backbones'+str(time)+'.dict')\n",
    "    new_backbone.load_state_dict(best_model_wts)\n",
    "    return new_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "899ef573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "**************************\n",
      "starting the 0 prune\n",
      "total parameters for backbone is now 2520887 after pruning, now start retrain\n",
      "now learning rate becomes 0.02\n",
      "step0 loss is 0.7674 \n",
      "step10 loss is 0.1481 \n",
      "step20 loss is 0.0814 \n",
      "step30 loss is 0.0668 \n",
      "step40 loss is 0.0604 \n",
      "step50 loss is 0.0558 \n",
      "step60 loss is 0.0525 \n",
      "step70 loss is 0.0501 \n",
      "step80 loss is 0.0476 \n",
      "step90 loss is 0.0451 \n",
      "step100 loss is 0.0428 \n",
      "step110 loss is 0.0411 \n",
      "step120 loss is 0.0391 \n",
      "step130 loss is 0.0368 \n",
      "step140 loss is 0.0353 \n",
      "step150 loss is 0.0333 \n",
      "step160 loss is 0.0320 \n",
      "step170 loss is 0.0303 \n",
      "step180 loss is 0.0289 \n",
      "step190 loss is 0.0272 \n",
      "step200 loss is 0.0260 \n",
      "step210 loss is 0.0253 \n",
      "step220 loss is 0.0235 \n",
      "step230 loss is 0.0226 \n",
      "step240 loss is 0.0215 \n",
      "step250 loss is 0.0208 \n",
      "step260 loss is 0.0199 \n",
      "step270 loss is 0.0189 \n",
      "step280 loss is 0.0187 \n",
      "step290 loss is 0.0179 \n",
      "*******epoch loss is 0.0615 \n"
     ]
    }
   ],
   "source": [
    "new_backbone = iterative_pruning(1, criterion, optimizer, lr_scheduler, original_backbone, new_backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80b176c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(new_backbone, '/home/cvte-vm/Deep_Feature_Extract/LoFTR/temp_backbone/random2.pth')\n",
    "torch.save(new_backbone.state_dict(), '/home/cvte-vm/Deep_Feature_Extract/LoFTR/temp_backbone/random2.dict')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39df5c61",
   "metadata": {},
   "source": [
    "# The following blocks of code is only for visualization, you don't need to run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540a174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in original_backbone.modules():\n",
    "    #print(m)\n",
    "    if isinstance( m, BasicBlock ):\n",
    "        print(m)\n",
    "        print('............................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b20dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original\n",
    "pytorch_total_params = sum(p.numel() for p in original_backbone.parameters())\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38da69fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2520887"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#new\n",
    "pytorch_total_params = sum(p.numel() for p in new_backbone.parameters())\n",
    "pytorch_total_params\n",
    "#4882176 for first prune\n",
    "#4111846 for second prune\n",
    "#3528448 for third prune\n",
    "#3258448 for fourth prune\n",
    "#3103365 for fifth prune\n",
    "#2772528 for sixth prune\n",
    "#2520887 for seventh prune\n",
    "#2338495 for eighth prune\n",
    "#2193625 for ninth prune\n",
    "#2080770 for tenth prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0152755",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params1 = sum(p.numel() for p in matcher.parameters())\n",
    "pytorch_total_params1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original weight\n",
    "for name, param in original_backbone.named_parameters():\n",
    "    print(name)\n",
    "    print(param)\n",
    "    print('..................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new weight\n",
    "for name, param in new_backbone.named_parameters():\n",
    "    print(name)\n",
    "    print(param)\n",
    "    print('..................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07200261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original\n",
    "original_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b68e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6774b2ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1381, 0.0192, 0.1413],\n",
       "         [0.9916, 0.0400, 0.6787]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce540c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetFPN_8_2(\n",
       "  (conv1): Conv2d(1, 73, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(73, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(96, 73, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(73, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(96, 73, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(73, 106, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(106, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(106, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(73, 59, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(59, 106, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(106, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(106, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(59, 138, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(138, 75, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(138, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(59, 75, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(75, 138, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(138, 75, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(138, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3_outconv): Conv2d(75, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (layer2_outconv): Conv2d(59, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (layer2_outconv2): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv2d(256, 196, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (layer1_outconv): Conv2d(73, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (layer1_outconv2): Sequential(\n",
       "    (0): Conv2d(196, 196, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv2d(196, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_backbone = torch.load('./temp_backbone/random.pth')\n",
    "random_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aff0fe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetFPN_8_2(\n",
       "  (conv1): Conv2d(1, 73, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(73, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(96, 73, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(73, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(96, 73, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(73, 106, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(106, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(106, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(73, 59, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(59, 106, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(106, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(106, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(59, 138, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(138, 75, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(138, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(59, 75, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(75, 138, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(138, 75, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(138, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3_outconv): Conv2d(75, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (layer2_outconv): Conv2d(59, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (layer2_outconv2): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv2d(256, 196, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (layer1_outconv): Conv2d(73, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (layer1_outconv2): Sequential(\n",
       "    (0): Conv2d(196, 196, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv2d(196, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seventh_backbone = torch.load('./temp_backbone/seventh_prune.pth')\n",
    "seventh_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b3eb6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNetFPN_8_2(\n",
       "  (conv1): Conv2d(1, 73, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(73, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(96, 73, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(73, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(96, 73, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(73, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(73, 106, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(106, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(106, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(73, 59, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(59, 106, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(106, 59, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(106, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(59, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(59, 138, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(138, 75, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(138, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(59, 75, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(75, 138, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (conv2): Conv2d(138, 75, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(138, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (bn2): BatchNorm2d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3_outconv): Conv2d(75, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (layer2_outconv): Conv2d(59, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (layer2_outconv2): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv2d(256, 196, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       "  (layer1_outconv): Conv2d(73, 196, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (layer1_outconv2): Sequential(\n",
       "    (0): Conv2d(196, 196, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (1): BatchNorm2d(196, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): LeakyReLU(negative_slope=0.01)\n",
       "    (3): Conv2d(196, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "untrain_backbone = torch.load('./temp_backbone/untrain.pth')\n",
    "untrain_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acca1d1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 1, 480, 640])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.randint(0,255,(8,1,480,640))/255.0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73e16304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 1, 1],\n",
       "        [1, 0, 1, 1],\n",
       "        [1, 0, 0, 1],\n",
       "        [0, 0, 1, 1]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randint(0,2,(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3836b9e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5039370078740157"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**6/127"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2862da85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
