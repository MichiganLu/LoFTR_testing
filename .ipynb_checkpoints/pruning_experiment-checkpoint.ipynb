{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe49e176",
   "metadata": {},
   "source": [
    "# The following blocks of codes are for pruning purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fc1d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.isdir(\"./temp_backbone\"):\n",
    "    os.mkdir(\"./temp_backbone\")\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "from src.utils.plotting import make_matching_figure\n",
    "from pathlib import Path\n",
    "import torch_pruning as tp\n",
    "from src.loftr.backbone import build_backbone\n",
    "from src.loftr.backbone.resnet_fpn import BasicBlock\n",
    "\n",
    "from einops.einops import rearrange\n",
    "\n",
    "from src.loftr.utils.position_encoding import PositionEncodingSine\n",
    "from src.loftr.loftr_module import LocalFeatureTransformer, FinePreprocess\n",
    "from src.loftr.utils.coarse_matching import CoarseMatching\n",
    "from src.loftr.utils.fine_matching import FineMatching\n",
    "from src.loftr import LoFTR, default_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8a1eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The default config uses dual-softmax.\n",
    "# The outdoor and indoor models share the same config.\n",
    "# You can change the default values like thr and coarse_match_type.\n",
    "_default_cfg = deepcopy(default_cfg)\n",
    "_default_cfg['coarse']['temp_bug_fix'] = True  # set to False when using the old ckpt\n",
    "original_backbone = build_backbone(_default_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a6d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "backbone_weight = OrderedDict()\n",
    "remain_weight = torch.load(\"./weights/indoor_ds_new.ckpt\")['state_dict']\n",
    "for k in list(remain_weight.keys()):\n",
    "    if k.startswith('matcher.backbone.'):\n",
    "        backbone_weight[k.replace('matcher.backbone.', '', 1)] = remain_weight.pop(k)\n",
    "original_backbone.load_state_dict(backbone_weight)\n",
    "new_backbone = deepcopy(original_backbone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1d81ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_model(model):\n",
    "    model.cpu()\n",
    "    DG = tp.DependencyGraph().build_dependency( model, torch.randn(1, 1, 480, 640) )\n",
    "    def prune_conv(conv, amount=0.2):\n",
    "        #weight = conv.weight.detach().cpu().numpy()\n",
    "        #out_channels = weight.shape[0]\n",
    "        #L1_norm = np.sum( np.abs(weight), axis=(1,2,3))\n",
    "        #num_pruned = int(out_channels * pruned_prob)\n",
    "        #pruning_index = np.argsort(L1_norm)[:num_pruned].tolist() # remove filters with small L1-Norm\n",
    "        strategy = tp.strategy.L1Strategy()\n",
    "        pruning_index = strategy(conv.weight, amount=amount)\n",
    "        plan = DG.get_pruning_plan(conv, tp.prune_conv, pruning_index)\n",
    "        plan.exec()\n",
    "    \n",
    "    block_prune_probs = [0.05, 0.05, 0.1, 0.1, 0.1, 0.1]\n",
    "    blk_id = 0\n",
    "    for m in model.modules():\n",
    "        if isinstance( m, BasicBlock ):\n",
    "            prune_conv( m.conv1, block_prune_probs[blk_id] )\n",
    "            prune_conv( m.conv2, block_prune_probs[blk_id] )\n",
    "            blk_id+=1\n",
    "    return model\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.RandomCrop((480,640)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5)\n",
    "])\n",
    "    \n",
    "def get_random_img(img_list):\n",
    "    img = cv2.imread(img_list[np.random.randint(0,len(img_list))], cv2.IMREAD_GRAYSCALE)\n",
    "    #img = cv2.resize(img, (640, 480))\n",
    "    img = torch.from_numpy(img)[None][None] / 255.     #return an image tensor\n",
    "    img = transform(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33af2313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prune model\n",
    "#prune_model(new_backbone)\n",
    "#new_backbone = torch.load('./temp_backbone/seventh_prune.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97962eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#you will need to first download the scannet 1500 and megadepth 1500 dataset\n",
    "#then change the directory below to the datasets location\n",
    "#create the retrain img list\n",
    "img_list = []\n",
    "for path in Path('/your_location_to/ScanNet/scannet_test_1500').rglob('*.jpg'):\n",
    "    img_list.append(str(path))\n",
    "for path in Path('/your_location_to/Megadepth/megadepth_test_1500').rglob('*.jpg'):\n",
    "    img_list.append(str(path))\n",
    "    \n",
    "#knowledge distillation\n",
    "#freeze original model\n",
    "for name, param in original_backbone.named_parameters():                \n",
    "    param.requires_grad = False\n",
    "original_backbone = original_backbone.cuda()\n",
    "original_backbone.eval()\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(new_backbone.parameters(), lr=0.0003, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95, last_epoch=-1, verbose=False)\n",
    "\n",
    "num_epoch = 4\n",
    "num_step = 300\n",
    "batch_size = 8\n",
    "\n",
    "best_model_wts = deepcopy(new_backbone.state_dict())\n",
    "def iterative_pruning(prune_time, criterion, optimizer, scheduler, original_backbone, new_backbone):\n",
    "    for time in range(prune_time):\n",
    "        print()\n",
    "        print('**************************')\n",
    "        print(f\"starting the {time} prune\")\n",
    "        #prune model\n",
    "        prune_model(new_backbone)\n",
    "        new_backbone = new_backbone.cuda()\n",
    "        new_backbone.train()\n",
    "        epoch_loss_old = 100\n",
    "        num_param = sum(p.numel() for p in new_backbone.parameters())\n",
    "        print(f\"total parameters for backbone is now {num_param} after pruning, now start retrain\")\n",
    "        #start retrain\n",
    "        for i in range(num_epoch):\n",
    "            print(f\"now learning rate becomes {optimizer.param_groups[0]['lr']}\")\n",
    "            running_loss = 0.0\n",
    "            for j in range(num_step):    \n",
    "                #first prepare data batch\n",
    "                img = get_random_img(img_list)             #first img in a batch\n",
    "                for bs in range(batch_size-1):\n",
    "                    img1 = get_random_img(img_list)\n",
    "                    img = torch.cat([img, img1], dim=0)    #concatenate in batch dimension, now img is a batch\n",
    "                img = img.cuda()\n",
    "                #finding loss\n",
    "                optimizer.zero_grad()\n",
    "                (layer2_label, layer4_label) = original_backbone(img) #soft label from teacher\n",
    "                (layer2_student, layer4_student) = new_backbone(img)  #student prediction\n",
    "                loss1 = criterion(layer2_student, layer2_label)\n",
    "                loss2 = criterion(layer4_student, layer4_label)\n",
    "                total_loss = loss1+loss2\n",
    "                total_loss.backward()\n",
    "                optimizer.step()        \n",
    "                if j%10 == 0:\n",
    "                    print('step'+str(j)+' loss is {:.4f} '.format(total_loss))\n",
    "\n",
    "                #calculating loss to check training result\n",
    "                running_loss += total_loss.item() * batch_size\n",
    "            epoch_loss = running_loss/(num_step*batch_size)\n",
    "            print('*******epoch loss is {:.4f} '.format(epoch_loss))\n",
    "\n",
    "            if epoch_loss < epoch_loss_old:    #save if loss gets smaller\n",
    "                epoch_loss_old = epoch_loss\n",
    "                best_model_wts = deepcopy(new_backbone.state_dict())\n",
    "            if epoch_loss < 0.07:             #good enough, start next prune\n",
    "                torch.save(new_backbone, './temp_backbone/backbones'+str(time)+'.pth')\n",
    "                torch.save(new_backbone.state_dict(), './temp_backbone/backbones'+str(time)+'.dict')\n",
    "                for g in optimizer.param_groups:\n",
    "                    g['lr'] = 0.0003*(2**time)\n",
    "                break                         \n",
    "            lr_scheduler.step()               #decay the learning rate for next epoch\n",
    "        \n",
    "        for g in optimizer.param_groups:      #reset learning rate for next prune\n",
    "            g['lr'] = 0.0003*(2**time)\n",
    "        if epoch_loss > 0.1:                 #if the loss cannot be optimized anymore, then stop pruning\n",
    "            print(f\"can only prune {time+1} time, cannot continue\")\n",
    "            new_backbone.load_state_dict(best_model_wts)\n",
    "            return new_backbone\n",
    "        else:                                  #when 0.07<loss<0.10, you still save the model\n",
    "            torch.save(new_backbone, './temp_backbone/backbones'+str(time)+'.pth')\n",
    "            torch.save(new_backbone.state_dict(), './temp_backbone/backbones'+str(time)+'.dict')\n",
    "    new_backbone.load_state_dict(best_model_wts)\n",
    "    return new_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ef573",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_backbone = iterative_pruning(10, criterion, optimizer, lr_scheduler, original_backbone, new_backbone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39df5c61",
   "metadata": {},
   "source": [
    "# The following blocks of code is only for visualization, you don't need to run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540a174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in original_backbone.modules():\n",
    "    #print(m)\n",
    "    if isinstance( m, BasicBlock ):\n",
    "        print(m)\n",
    "        print('............................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b20dab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original\n",
    "pytorch_total_params = sum(p.numel() for p in original_backbone.parameters())\n",
    "pytorch_total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da69fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "pytorch_total_params = sum(p.numel() for p in new_backbone.parameters())\n",
    "pytorch_total_params\n",
    "#4882176 for first prune\n",
    "#4111846 for second prune\n",
    "#3528448 for third prune\n",
    "#3258448 for fourth prune\n",
    "#3103365 for fifth prune\n",
    "#2772528 for sixth prune\n",
    "#2520887 for seventh prune\n",
    "#2338495 for eighth prune\n",
    "#2193625 for ninth prune\n",
    "#2080770 for tenth prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0152755",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_total_params1 = sum(p.numel() for p in matcher.parameters())\n",
    "pytorch_total_params1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb47e913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original weight\n",
    "for name, param in original_backbone.named_parameters():\n",
    "    print(name)\n",
    "    print(param)\n",
    "    print('..................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80be690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#new weight\n",
    "for name, param in new_backbone.named_parameters():\n",
    "    print(name)\n",
    "    print(param)\n",
    "    print('..................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07200261",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original\n",
    "original_backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b68e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_backbone"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
